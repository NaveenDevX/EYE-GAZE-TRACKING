# ğŸ§ ğŸ‘€ Multilingual Eye-Tracking Communication System  
### AI-Powered Augmentative & Alternative Communication (AAC)

A low-cost, webcam-based **eye-tracking communication application** that enables individuals with severe motor disabilities to communicate using **eye and head movements**, enhanced with **predictive language models** and **multilingual support**.

---

## ğŸš€ Overview

Traditional input devices such as keyboards and mice are inaccessible to many individuals with motor impairments. This project introduces an **AI-driven Augmentative and Alternative Communication (AAC) system** that allows users to type using eye gaze and receive intelligent word suggestions in real time.

The system is designed to be:
- Non-invasive
- Affordable
- Language-inclusive
- Real-time and responsive

---

## âœ¨ Key Features

- ğŸ‘ **Webcam-Based Eye & Head Tracking**  
  Uses computer vision and CNNs without requiring specialized hardware.

- âŒ¨ï¸ **Gaze-Controlled Virtual Keyboard**  
  Characters are selected using eye fixation and head orientation.

- ğŸ¤– **Predictive Text & Language Modeling**  
  Context-aware word and sentence recommendations using LSTM and Transformer models.

- ğŸŒ **Multilingual Support**  
  Supports multiple languages and scripts using multilingual tokenizers such as mBERT and XLM-R.

- ğŸ”Š **Text-to-Speech (TTS)**  
  Converts typed text into spoken output in the selected language.

- âš¡ **Real-Time Performance**  
  Optimized for low latency and smooth user interaction.

---

## ğŸ—ï¸ System Architecture

1. Face and eye detection using webcam input  
2. Region of Interest (ROI) extraction  
3. CNN-based gaze estimation  
4. Temporal smoothing and context management  
5. Predictive language modeling  
6. Multilingual virtual keyboard UI  
7. Text-to-speech output  

---

## ğŸ§  Technologies Used

- **Language:** Python  
- **Computer Vision:** OpenCV  
- **Deep Learning:** CNN, LSTM, Transformer models  
- **NLP:** n-gram models, mBERT, XLM-R  
- **Eye Tracking:** Webcam-based gaze estimation  
- **UI:** Virtual keyboard with Unicode rendering  

---

## ğŸ“Š Evaluation Metrics

The system performance is evaluated using:
- Accuracy
- Precision
- Recall
- F1-Score
- Typing speed
- Prediction accuracy

Experimental results demonstrate improved performance compared to traditional AAC systems.

---

## ğŸ¯ Use Cases

- Assistive communication for individuals with motor disabilities
- Augmentative and Alternative Communication (AAC) research
- Inclusive humanâ€“computer interaction systems
- AI-based accessibility solutions


---

## ğŸ› ï¸ Installation & Setup

bash
git clone https://github.com/your-username/eye-tracking-aac.git
cd eye-tracking-aac
pip install -r requirements.txt
python main.py
ğŸ”® Future Enhancements

-Blink / wink-based selection confirmation
-Improved personalized prediction using adaptive learning
-Mobile and web deployment
-Advanced multilingual speech synthesis
-User studies for cognitive load evaluation

ğŸ‘¨â€ğŸ’» Author

G. G. Naveen
B.Tech â€“ Artificial Intelligence and Data Science
ğŸ“œ License

This project is developed for academic and research purposes.
License details can be added as required.

